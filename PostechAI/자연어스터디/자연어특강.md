## 자연어 특강 

9/14 금 10:00~ 12:00 , 13:00~15:00

Postech knowledge & Language Engineering 이종혁 교수



일반적인 연구 토픽은 한번 시작하면 짧게는 일년 안에, 30~40년 이내에 정복

인간의 언어는 만만치 않다.

인간의 존재가치로서 스스로 어떻게 행동하는지 이해하지 못한다.

잘 모르는데 만들겠다 -> 인공지능



* 지능이란 무엇인가?

어떤 측면에서 직관적으로 똑똑하다고 하는가?



궁극적으로 Ultimate goal은 인간이 원하는 바 까지 가능하다.



* "기계가 인간 대신, 말할 수 있다면 뭘할수 있을까?"



기업이 필요한 언어대리 시스템은 특정한  목적이 있다.

그 목적을 달성하기 위해서, 대화의 시스템 back 단 처리가 필요하다.



딥러닝을 써서, seq2seq모델을 썼을 때, 오늘 날 챗봇 시스템보다 쉽게 구현이 가능하다.



* 감성과 감정

감성 : 정보를 받아들이기 위한 인간의 모든 센서에서 받아들이는 말초적인 느낌 ex) 감성 공학

감정 : 감성을 토대로 조금 더 두뇌의 활동이 접목되어 느끼는 것 ex)정서



document 에는 사실정보가 있다 . fact를 제외하고는 주관적인 의견이 들어가있는 의견

애매와 모호는 다른단어다

애매하다 : 하나가 여러개로 해석될 수 있다.

모호하다 : 기준이 분명하지 않다.



* 정서분석(sentimentary analysis)

: 감성과는 다른개념.



말을 잘해도 문제인식을 잘 못하면, 문제이다.-> 컴퓨터 비전



* 우리가 외국어 공부를 할 때, 우선 단어를 공부한다.

  학습할 때 중요한건, 일주일 있다가 또 반복하면 2주 가고, 또 하면 한달 가고, 한달있다가 또 가면, 6개월간다.

  단어를 학습하고 문법을 공부한다.

  문장을 통째로 외운다.

  문화가 달라서 native가 될수 없다.

  실제 지식(Real Knowledge) 이 필요하다. 



Linquistics

 : 언어의 역사를 이해하고, 언어의 보편적인 기반이 될 수 있는 문법을 찾는것이 언어학

Psychology

 : 인간이 하는 방식과 다른 존재가 하는 방식은 다를 수 있다. 똑같은 자극에 대해 인간과 다른 존재는 어떻게 이해하는지에 대해 이해하는 학문

NLP

 : 언어의 본질이 무엇이던지, 사람이 인간의 언어라고 느낄 수 있으면 된다.

패턴 매칭 기반의 전처리 과정 및 생성과정이 포함되어있다.



##### NLP Application

* : 자연어 처리를 할 수 있게된다면, 어떤 일을 할 수 있을까?
  * Text Classification : 이미 정해진 카테고리set(범주)에 할당
  * Text Clustering : 사전에 카테고리가 정해져있지 않지만 , 군집화하는 것
  * Text Summarization : 하나의 문서 내용을 요약해서, 원래 사이즈보다 작은 사이즈로 축약. 단, 축약할 때 가장 중요한 점은 중요내용이 누락되지 않아야 한다. 
  * single document summarization : 각각의 문서에서 요약된 내용을 어떻게 merge할건지 (조금더 어려움)
  * multi document summarization : 여러개의 문서에서 내용을 요약
* Machine Tanslation : Rule-based MT , Statistical MT , Neural MT( RNN Encoder-Decoder)



* Deep Learning
  * 뉴런 : 사람의 세포 신경을 흉내내어 컴퓨터 내부에서 뉴런을 표현한다. 
  * 뉴런 하나하나에서 인풋을 받아 하나의 signal을 아웃풋으로 낸다. 
  * artificial 뉴런은 심플한 방식으로 반응한다.
  * 하나의 받는 뉴런들이 또 다양한 뉴런들에게 시그널을 내보내고 또 다양한 뉴런은 하나의 뉴런들에게 아웃풋을 낸다.
  * 인풋과 아웃풋을 정하면, 컴퓨터가 스스로 일련의 인공신경망 과정을 거쳐 각각 뉴런으로 전해지는 값들의 weight을 정하는 과정을 deep learning이라고 한다.
  * End to End 시스템
  * ![ë´ë°ë¤í¸ìí¬ì ëí ì´ë¯¸ì§ ê²ìê²°ê³¼](https://upload.wikimedia.org/wikipedia/commons/thumb/4/46/Colored_neural_network.svg/300px-Colored_neural_network.svg.png)
  * 장점 : 모델이 정해지면, 누구든 구현이 쉽다.
  * 단점 : 과정을 모르기 때문에 improve시키는것이 어렵다.
* Sentiment Analysis
  * 사실 기반의 기사
  * 의견 기사
* Information Extraction
  * 필요한 정보만을 추출한다. 각각의 column에 맞는 record를 입력시키는 과정.

* Two Broad Areas : 글과 말은 구분할것

  * 종류 : 
    * Text processing
      * Language analysis
      * Language generation
    * Speech processing
      * Speech recognition
      * Speech Synthesis
  * 생성보다 분석이 더 어렵다
  * 말로 표현되어있는 것을 테이블로 만드는 과정이 language analysis

* Language Analysis 과정

  * Speech Recognition(Written utterance)
  * Lexical analysis(어휘 분석) : Word Structure(Morphemes,words)
  * Syntactic analysis : Sentence Structure(Sentence) => 문장이 주어질때 문장 구조를 파악할 때 , 좁은의미의 parsing이다.
  * semantic analysis : 단어와 문장의 의미 
  * Discourse analysis : Relations b/w sentences (앞뒤문장의 관계)
  * Pragmatic analysis : 말의 목적 파악(화용 분석)
  * 각각의 level에서 적절한 application을 활용하여 분석한다.

* Language Analysis 예시

  * 개가 아이를 쫓아간다. -> 의도 : 놀고싶음

  * 아이는 무서워서 도망간다. -> 의도 : 공포감

  * 지나가던 행인이 개의 주인에게 "A dog is chasing a boy on the playground"라고 말한다. -> 의도 : 개를 붙잡으라는 뜻

  * "A dog is chasing a boy on the playground." > Lexical analysis(part-of-speech tagging) 

  * Det , Noun , Aux , Verb , Det , Noun, Prep , Det , Noun (parsing)

    * NP , VG , NP , NP
      * VP , PP
        * NP , VP
          * S

  * Semantic analysis

    ```
    - Dog(d1).
    - Boy(b1).
    - Playground(p1).
    - Chasing(d1,b1,p1).
    - +Scared(x) if Chasing(___,x,___)
    -> Scared(b1) : Inference
    ```

  * Pragmatic analysis(speech act) 

    *  A person saying that "this may be reminding another person to get the doh back"

* NLP Pipeline - Analysis Tasks

  * Tokenization & Segmentation
  * Lexical analysis
    * 형태소 분석, POS 태깅(Morphological analysis & POS tagging)
    * 개체명 인식(Named entity recognition)
  * Syntactic analysis
    * 얕은 구조화(Shallow parsing : Chunking)
    * 깊은 구조화(Full parsing)
  * Semantic analysis
    * 워드 중의성 해소(Word sense disambiguation)
    * 구조 속 역할 라벨링(Semantic role labeling)
  * Pragmatic & Discourse analysis
    * 말로 반응(Speech act detection)
    * Anaphora resolution

* Segmentation

  * 단어의 경계를 찾는 것 : 언어별로 다르다.

* Morphological Analysis : 가능한 것을 모두 추출해 낸다

  * 문장 속 시퀀스 정보를 받아 단어로 잘라낸다.
  * 단어의 형태소 시퀀스에 라벨링한다
  * 형태소 시퀀스를 표제어로 변환한다.

* POS Tagging : 추출된 것들을 하나로 선택한다.

  * 품사 태그의 애매성을 해소한다.
  * 품사 후보의 여러개에서 하나를 선택하는 작업
  * 만약, POS Tagging에서 하나라도 틀리면 그 뒤의 작업이 전부 에러가 난다

* Named Entity Recognotion(NER)

  * 개체명 인식
  * 일반적으로 사용하는 말을 해석하기 위해서는 표제어 기준으로 15만~20만 단어가 필요하다.
  * 조사나 어미는 개수가 한정되어있다.
  * 일반 명사나 동사는 개수가 끊임없이 만들어진다. 그러나 순식간에 많아지지 않는다.
  * 기술용어+고유명사는 순식간에 끊임없이 만들어진다.(Unkown Node)
  * PLO가 기본(이름,위치,조직명)

* Shallow Parsing(Chunking)
  * 문장에 주어질 때, Phrase Boundary 를 찾아주는 역할 
  * Phrase 내부 구조는 parsing 하지 않음
  * Basic Phrase 형태
* Syntactic Parsing
  * Syntactic의 두가지 타입
    * Constituency(PS-tree) : 작은 컴바인된 언어형태가 큰 언어형태로 컴바인 되는 형태 
    * Dependency(D-tree) : head와 dependent가 있고 의존적인 형태이다. 헤드가 디펜던트에 영향력을 행사한다. 단어 자체의 영향을 주는게 아니라, syntactic level에서의 relation을 표현함.머신러닝관점에서는 D-tree가 PS-tree보다 용이하다. 그리고 한국어도 어순이 자유로우므로 D-tree가 더 적합하다. ex) eat라는 동사를 완벽하게 표현하기 위한 argument가 존재하는데 그 argument는 apples등등이 있다. 
  * Syntactic structure 에 따라 의미가 매우 달라질 수 있다.
    * He ate some dessert with a fork
    * 그는 먹었다 디저트들을 포크로
    * 그는 먹었다 포크가 딸린 디저트들을
  * voice 는 음성이 아닌 형태(능동태,수동태)를 의미한다.
  * 의미가 결정되어있을 때,  음성을 피동형이나 능동형으로 생성할건지에 대한 논문을 썼다.(by Prof.Lee)

* Word Sense Disambiguation(WSD)
  * 해당 문장에서 그 단어가 문장내에서 어떠한 역할을 하는지 결정짓는 것
  * 문장에 나오는 의미의 중의성을 해소하는 문제는 언제나 어렵고 그 문제해법은 머신러닝으로 해결할 수 가 없다.
  * 접근법 : 
    * All-words task : 모든 단어의 중의성을 해소하는 것
    * Lexical sample task : 특정분야에서 사용하는 단어 20개든 30개든의 중의성만 해소하더라도 매우 유용하다. 

* Semantic Role Labeling(SRL)
  * ''문장 중에 어느 파트가 그 이벤트의 어떤 역할을 하느냐'' 를 찾아내는 것이 Sematic Rolling 이다.
  * 행위 당사자 : agent
  * 이벤트 : Predicate
  * 테마 : Theme
  * 장소 : Location
  * 시간 : Time
  * 어순이 바뀔수도 있는데, 단어가 어떤 위치에 있는 경우라도 상관없이 의미적으로 Semantic Role은 일정하다.
* Classical vs Deep Learning
  * 기존 방식의 input output 방식의 머신러닝은 인간이 과정을 이해할 수 있었다.
  * Deep Learning 방식은 사람이 blind 방식으로 이해할 수 없다.
    * Unit간에서  RealNumber의 signal이 이동하는 동안 weight가 어떻게 변하는지 확인할 수 없다. 왜냐하면, 그 signal이 어떤의미를 갖는지 알수가 없기 때문이다. raw level의 어떠한 의미있는 값이 전달되는 것을 사람이 확인할 수 없기 때문이다. fraction이 수천 , 수만개가 존재하므로 그것을 파악하는 것을 불가능 하다. Squash하다.
    * 경험에 의해서 인식률 개선에 대한 방안을 강구해야한다.
    * 전체를 다시한번 학습해보는 방법밖에 없다.

## NLP Applications

### Search Engines

* Web Search Engines
* Indexing Pipeline
  * Friends , Romans , Countrymen.
  * Friends / Romans / Countrymen
  * Friend / Roman / Countrymen -> 표준형으로 indexing하여 검색
  * Friend => 2->4-> 
  * Roman=> 1->2->
  * Country=>13->16->
* 현재 검색 엔진들에서 차용하는 검색 알고리즘 : 검색 키워드와 연관성있는 단어들의 빈도수로 게시물을 검색한다.
* Index Construction : Parsing
  * Step-1 : A list of <term,docID> pairs("postings")
  * 용어별 속해있는 doc아이디를 딕셔너리리스트로 파싱한다.
* Index Construction : Sorting
  * Step-2 : merge Sort를 사용.
  * 머지소팅을 사용하여 분류한다.
* Index Construction : Splitting
  * Step-3 : 한 문서에서 나오는 빈도수(IDF:Inverse Document Frequency?) 와 전체 문서에서 나오는 빈도수(TF?) 를 곱하여 그 값(TF-IDF)이 높은 문서를 검색해준다.
* 정보 검색 엔진에서 중요한 점은 전체 문서에서 몇 %나 찾아냈느냐.  변호를 위한 법정보 검색에서 중요한 점은 얼마나 다 검색이 되었느냐. 정확도 : Precision , 재현율 : recall

<hr> 

### Text Mining

* Aspect-Based Opinion Summary
  * WordEmbedding -< lexicon(감정사전) 이 필요없음
* Question/Answering
  * Question Processing
    * Tokenization & POS Tagging
    * Question Parsing
    * Word Sense Disambiguation
    * Answer Type Identification
    * Keyword Expansion
  * Search
    * Query Composition
    * Search Engine
  * Answer Extraction
    * Paragraph Filtering
    * Named Entity Recognition
    * Answer Identification
    * Answer Ranking
* Information Extraction : Sentence Compaction(문장 유의미최적화)